"""
pytest ì„¤ì • ë° ê³µí†µ í”½ìŠ¤ì²˜
"""

import pytest
import sys
import os
import tempfile
import shutil
from pathlib import Path
from datetime import datetime, time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.models import Team, InterviewSlot, Schedule, SchedulingOption


@pytest.fixture(scope="session")
def test_data_dir():
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ í”½ìŠ¤ì²˜"""
    data_dir = Path(__file__).parent / "test_data"
    data_dir.mkdir(exist_ok=True)
    return data_dir


@pytest.fixture(scope="session")
def temp_output_dir():
    """ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ í”½ìŠ¤ì²˜"""
    temp_dir = Path(__file__).parent / "temp_output"
    temp_dir.mkdir(exist_ok=True)
    
    yield temp_dir
    
    # í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ì •ë¦¬
    if temp_dir.exists():
        shutil.rmtree(temp_dir)


@pytest.fixture
def sample_teams():
    """ìƒ˜í”Œ íŒ€ ë°ì´í„° í”½ìŠ¤ì²˜"""
    return [
        Team(
            name="í•œêµ­ëŒ€í•™êµíŒ€",
            email="korea@university.ac.kr",
            contact="010-1234-5678",
            preferred_times=["14:00", "15:00"],
            avoid_interviewers=["ê¹€êµìˆ˜"]
        ),
        Team(
            name="í…Œí¬ìŠ¤íƒ€íŠ¸ì—…",
            email="contact@techstartup.co.kr",
            contact="010-9876-5432",
            preferred_times=["10:00", "11:00"],
            avoid_interviewers=[]
        ),
        Team(
            name="ì°½ì—…ë™ì•„ë¦¬",
            email="startup@club.ac.kr",
            contact="010-5555-6666",
            preferred_times=["16:00", "17:00"],
            avoid_interviewers=["ì´êµìˆ˜"]
        ),
        Team(
            name="í˜ì‹ íŒ€",
            email="innovation@team.com",
            contact="010-7777-8888",
            preferred_times=["09:00", "10:00"],
            avoid_interviewers=[]
        ),
        Team(
            name="ì•Œê³ ë¦¬ì¦˜íŒ€",
            email="algo@team.com",
            contact="010-9999-0000",
            preferred_times=["13:00", "14:00"],
            avoid_interviewers=["ê¹€êµìˆ˜", "ë°•êµìˆ˜"]
        )
    ]


@pytest.fixture
def sample_interview_slots():
    """ìƒ˜í”Œ ë©´ì ‘ ìŠ¬ë¡¯ í”½ìŠ¤ì²˜"""
    slots = []
    interviewers = ["ê¹€êµìˆ˜", "ì´êµìˆ˜", "ë°•êµìˆ˜", "ìµœêµìˆ˜"]
    times = [
        time(9, 0), time(10, 0), time(11, 0), time(13, 0),
        time(14, 0), time(15, 0), time(16, 0), time(17, 0)
    ]
    
    for interviewer in interviewers:
        for slot_time in times:
            slots.append(InterviewSlot(
                date=datetime(2024, 1, 15),
                time=slot_time,
                interviewer=interviewer,
                location=f"ë©´ì ‘ì‹¤{interviewers.index(interviewer) + 1}"
            ))
    
    return slots


@pytest.fixture
def sample_schedules(sample_teams, sample_interview_slots):
    """ìƒ˜í”Œ ìŠ¤ì¼€ì¤„ í”½ìŠ¤ì²˜"""
    return [
        Schedule(
            team=sample_teams[0],
            slot=sample_interview_slots[20],  # ê¹€êµìˆ˜ê°€ ì•„ë‹Œ ìŠ¬ë¡¯
            priority_score=0.9
        ),
        Schedule(
            team=sample_teams[1],
            slot=sample_interview_slots[8],   # 10:00 ìŠ¬ë¡¯
            priority_score=1.0
        ),
        Schedule(
            team=sample_teams[2],
            slot=sample_interview_slots[30],  # ì´êµìˆ˜ê°€ ì•„ë‹Œ 16:00 ìŠ¬ë¡¯
            priority_score=0.8
        )
    ]


@pytest.fixture
def sample_scheduling_options(sample_schedules):
    """ìƒ˜í”Œ ìŠ¤ì¼€ì¤„ë§ ì˜µì…˜ í”½ìŠ¤ì²˜"""
    return [
        SchedulingOption(
            name="ì²« ë²ˆì§¸ ì„ í˜¸ë„ ìš°ì„ ",
            description="íŒ€ì˜ ì²« ë²ˆì§¸ ì„ í˜¸ ì‹œê°„ì„ ìš°ì„ ì‹œí•©ë‹ˆë‹¤",
            schedules=sample_schedules,
            optimization_score=0.85,
            constraint_violations=0
        ),
        SchedulingOption(
            name="ì‹œê°„ ë¶„ì‚°",
            description="ë©´ì ‘ ì‹œê°„ì„ ê³ ë¥´ê²Œ ë¶„ì‚°ì‹œí‚µë‹ˆë‹¤",
            schedules=sample_schedules,
            optimization_score=0.75,
            constraint_violations=1
        ),
        SchedulingOption(
            name="ê·¸ë£¹ ê· í˜•",
            description="ë©´ì ‘ê´€ë³„ ë°°ì •ì„ ê· ë“±í•˜ê²Œ í•©ë‹ˆë‹¤",
            schedules=sample_schedules,
            optimization_score=0.80,
            constraint_violations=0
        ),
        SchedulingOption(
            name="ì˜¤ì „/ì˜¤í›„ ê· í˜•",
            description="ì˜¤ì „ê³¼ ì˜¤í›„ ë©´ì ‘ì„ ê· ë“±í•˜ê²Œ ë°°ë¶„í•©ë‹ˆë‹¤",
            schedules=sample_schedules,
            optimization_score=0.70,
            constraint_violations=2
        ),
        SchedulingOption(
            name="ì œì•½ì¡°ê±´ ìš°ì„ ",
            description="ëª¨ë“  ì œì•½ì¡°ê±´ì„ ìµœëŒ€í•œ ë§Œì¡±ì‹œí‚µë‹ˆë‹¤",
            schedules=sample_schedules,
            optimization_score=0.90,
            constraint_violations=0
        )
    ]


@pytest.fixture
def temp_pdf_file():
    """ì„ì‹œ PDF íŒŒì¼ í”½ìŠ¤ì²˜"""
    with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
        pdf_path = tmp_file.name
        # ì‹¤ì œ PDF ë‚´ìš©ì€ í…ŒìŠ¤íŠ¸ì—ì„œ ëª¨í‚¹ë¨
        tmp_file.write(b"Mock PDF content")
    
    yield pdf_path
    
    # ì •ë¦¬
    if os.path.exists(pdf_path):
        os.unlink(pdf_path)


@pytest.fixture
def temp_excel_file():
    """ì„ì‹œ Excel íŒŒì¼ í”½ìŠ¤ì²˜"""
    with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp_file:
        excel_path = tmp_file.name
    
    yield excel_path
    
    # ì •ë¦¬
    if os.path.exists(excel_path):
        os.unlink(excel_path)


@pytest.fixture(autouse=True)
def setup_test_environment():
    """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • (ëª¨ë“  í…ŒìŠ¤íŠ¸ì— ìë™ ì ìš©)"""
    # í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['TESTING'] = 'true'
    os.environ['LOG_LEVEL'] = 'DEBUG'
    
    yield
    
    # í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬
    if 'TESTING' in os.environ:
        del os.environ['TESTING']
    if 'LOG_LEVEL' in os.environ:
        del os.environ['LOG_LEVEL']


@pytest.fixture
def large_team_dataset():
    """ëŒ€ê·œëª¨ íŒ€ ë°ì´í„°ì…‹ í”½ìŠ¤ì²˜ (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš©)"""
    teams = []
    for i in range(70):  # ì‹¤ì œ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” 70ê°œ íŒ€
        team = Team(
            name=f"íŒ€{i+1:02d}í˜¸",
            email=f"team{i+1:02d}@test{(i % 10) + 1}.com",
            contact=f"010-{i+1:04d}-{i+1:04d}",
            preferred_times=[
                f"{9 + (i % 9)}:00", 
                f"{10 + (i % 9)}:00"
            ],
            avoid_interviewers=[f"êµìˆ˜{(i % 4) + 1}"] if i % 5 == 0 else []
        )
        teams.append(team)
    
    return teams


@pytest.fixture(scope="session")
def performance_baseline():
    """ì„±ëŠ¥ ê¸°ì¤€ì„  í”½ìŠ¤ì²˜"""
    return {
        "pdf_extraction_max_time": 10.0,      # PDF ì¶”ì¶œ ìµœëŒ€ ì‹œê°„ (ì´ˆ)
        "email_validation_max_time": 5.0,     # ì´ë©”ì¼ ê²€ì¦ ìµœëŒ€ ì‹œê°„ (ì´ˆ)  
        "scheduling_max_time": 60.0,          # ìŠ¤ì¼€ì¤„ë§ ìµœëŒ€ ì‹œê°„ (ì´ˆ)
        "excel_generation_max_time": 30.0,    # Excel ìƒì„± ìµœëŒ€ ì‹œê°„ (ì´ˆ)
        "max_memory_usage_mb": 500,           # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        "large_dataset_teams": 70,            # ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ íŒ€ ìˆ˜
        "expected_accuracy": 0.95             # ì˜ˆìƒ ì •í™•ë„
    }


# pytest ì„¤ì •
def pytest_configure(config):
    """pytest ì„¤ì •"""
    # ì»¤ìŠ¤í…€ ë§ˆì»¤ ë“±ë¡
    config.addinivalue_line(
        "markers", "slow: mark test as slow running"
    )
    config.addinivalue_line(
        "markers", "integration: mark test as integration test"
    )
    config.addinivalue_line(
        "markers", "performance: mark test as performance test"
    )
    config.addinivalue_line(
        "markers", "korean: mark test as Korean text processing test"
    )


def pytest_collection_modifyitems(config, items):
    """í…ŒìŠ¤íŠ¸ ì•„ì´í…œ ìˆ˜ì •"""
    # í†µí•© í…ŒìŠ¤íŠ¸ì™€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë§ˆì»¤ ìë™ ì¶”ê°€
    for item in items:
        if "integration" in item.nodeid:
            item.add_marker(pytest.mark.integration)
        if "performance" in item.nodeid or "large" in item.nodeid:
            item.add_marker(pytest.mark.performance)
        if "korean" in item.nodeid or "í•œêµ­" in str(item):
            item.add_marker(pytest.mark.korean)


def pytest_runtest_setup(item):
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì „ ì„¤ì •"""
    # ëŠë¦° í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸° (í•„ìš”ì‹œ)
    if item.get_closest_marker("slow"):
        if item.config.getoption("--fast"):
            pytest.skip("Skipping slow test in fast mode")


def pytest_addoption(parser):
    """pytest ëª…ë ¹í–‰ ì˜µì…˜ ì¶”ê°€"""
    parser.addoption(
        "--fast",
        action="store_true",
        default=False,
        help="Run fast tests only, skip slow tests"
    )
    parser.addoption(
        "--integration",
        action="store_true", 
        default=False,
        help="Run integration tests only"
    )
    parser.addoption(
        "--performance",
        action="store_true",
        default=False,
        help="Run performance tests only"
    )


# í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
def pytest_terminal_summary(terminalreporter, exitstatus, config):
    """í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    if hasattr(terminalreporter, 'stats'):
        passed = len(terminalreporter.stats.get('passed', []))
        failed = len(terminalreporter.stats.get('failed', []))
        skipped = len(terminalreporter.stats.get('skipped', []))
        
        print(f"\n{'='*60}")
        print(f"ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*60}")
        print(f"í†µê³¼: {passed}ê°œ")
        print(f"ì‹¤íŒ¨: {failed}ê°œ") 
        print(f"ê±´ë„ˆëœ€: {skipped}ê°œ")
        print(f"ì¢…ë£Œ ìƒíƒœ: {'ì„±ê³µ' if exitstatus == 0 else 'ì‹¤íŒ¨'}")
        print(f"{'='*60}")
        
        if exitstatus == 0:
            print(f"ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸš€ ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œì´ í”„ë¡œë•ì…˜ ì¤€ë¹„ ìƒíƒœì…ë‹ˆë‹¤.")
        else:
            print(f"âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")