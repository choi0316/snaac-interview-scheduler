#!/usr/bin/env python3
"""
ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì „ì²´ ì‹œìŠ¤í…œì˜ í…ŒìŠ¤íŠ¸ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³ 
ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python run_tests.py                  # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    python run_tests.py --fast           # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰  
    python run_tests.py --integration    # í†µí•© í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
    python run_tests.py --performance    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
    python run_tests.py --coverage       # ì½”ë“œ ì»¤ë²„ë¦¬ì§€ í¬í•¨
"""

import sys
import os
import subprocess
import time
import argparse
from pathlib import Path
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))


class TestRunner:
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.test_dir = self.project_root / "tests"
        self.results = {}
        
    def run_command(self, command, capture_output=True):
        """ëª…ë ¹ì–´ ì‹¤í–‰"""
        try:
            if capture_output:
                result = subprocess.run(
                    command, 
                    shell=True, 
                    capture_output=True, 
                    text=True,
                    cwd=self.project_root
                )
                return result.returncode, result.stdout, result.stderr
            else:
                result = subprocess.run(command, shell=True, cwd=self.project_root)
                return result.returncode, "", ""
        except Exception as e:
            return 1, "", str(e)
    
    def check_dependencies(self):
        """ì˜ì¡´ì„± í™•ì¸"""
        print("ğŸ” ì˜ì¡´ì„± í™•ì¸ ì¤‘...")
        
        # pytest ì„¤ì¹˜ í™•ì¸
        returncode, stdout, stderr = self.run_command("python -m pytest --version")
        if returncode != 0:
            print("âŒ pytestê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...")
            self.run_command("pip install pytest", capture_output=False)
        else:
            print(f"âœ… pytest ì„¤ì¹˜ë¨: {stdout.strip()}")
        
        # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
        required_packages = [
            "pdfplumber", "ortools", "openpyxl", "streamlit", 
            "jinja2", "pytest-cov", "pytest-html", "psutil"
        ]
        
        missing_packages = []
        for package in required_packages:
            returncode, _, _ = self.run_command(f"python -c 'import {package.replace('-', '_')}'")
            if returncode != 0:
                missing_packages.append(package)
        
        if missing_packages:
            print(f"âš ï¸  ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
            print("ğŸ“¦ requirements.txtì—ì„œ ì„¤ì¹˜ ì¤‘...")
            self.run_command("pip install -r requirements.txt", capture_output=False)
        else:
            print("âœ… ëª¨ë“  ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    def run_unit_tests(self):
        """ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nğŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        unit_test_files = [
            "test_models.py",
            "test_pdf_extractor.py", 
            "test_scheduler_engine.py",
            "test_excel_generator.py",
            "test_email_system.py"
        ]
        
        start_time = time.time()
        total_passed = 0
        total_failed = 0
        
        for test_file in unit_test_files:
            test_path = self.test_dir / test_file
            if test_path.exists():
                print(f"  ğŸ“‹ {test_file} í…ŒìŠ¤íŠ¸ ì¤‘...")
                
                command = f"python -m pytest {test_path} -v --tb=short"
                returncode, stdout, stderr = self.run_command(command)
                
                # ê²°ê³¼ íŒŒì‹±
                if "failed" in stdout.lower():
                    failed = int(stdout.split("failed")[0].split()[-1]) if "failed" in stdout else 0
                else:
                    failed = 0
                
                if "passed" in stdout.lower():
                    passed = int(stdout.split("passed")[0].split()[-1]) if "passed" in stdout else 0
                else:
                    passed = 0
                
                total_passed += passed
                total_failed += failed
                
                if returncode == 0:
                    print(f"    âœ… {test_file}: {passed}ê°œ í†µê³¼")
                else:
                    print(f"    âŒ {test_file}: {passed}ê°œ í†µê³¼, {failed}ê°œ ì‹¤íŒ¨")
        
        unit_test_time = time.time() - start_time
        
        self.results['unit_tests'] = {
            'passed': total_passed,
            'failed': total_failed,
            'time': unit_test_time
        }
        
        print(f"ğŸ“Š ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {total_passed}ê°œ í†µê³¼, {total_failed}ê°œ ì‹¤íŒ¨ ({unit_test_time:.2f}ì´ˆ)")
        return total_failed == 0
    
    def run_integration_tests(self):
        """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        start_time = time.time()
        
        integration_test_path = self.test_dir / "test_integration.py"
        if not integration_test_path.exists():
            print("âŒ í†µí•© í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        command = f"python -m pytest {integration_test_path} -v --tb=short -s"
        returncode, stdout, stderr = self.run_command(command, capture_output=False)
        
        integration_time = time.time() - start_time
        
        self.results['integration_tests'] = {
            'success': returncode == 0,
            'time': integration_time
        }
        
        if returncode == 0:
            print(f"âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ ({integration_time:.2f}ì´ˆ)")
        else:
            print(f"âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({integration_time:.2f}ì´ˆ)")
        
        return returncode == 0
    
    def run_performance_tests(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        start_time = time.time()
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ íŠ¹ì • í•­ëª©ë“¤
        performance_commands = [
            f"python -m pytest {self.test_dir}/test_integration.py::TestCompleteWorkflow::test_large_scale_workflow -v",
            f"python -m pytest {self.test_dir}/test_integration.py::TestCompleteWorkflow::test_performance_benchmarking -v",
            f"python -m pytest {self.test_dir}/test_scheduler_engine.py::TestSchedulerEngine::test_parallel_processing_performance -v"
        ]
        
        performance_results = []
        
        for command in performance_commands:
            print(f"  ğŸƒ {command.split('::')[-1] if '::' in command else 'ì„±ëŠ¥ í…ŒìŠ¤íŠ¸'} ì‹¤í–‰ ì¤‘...")
            returncode, stdout, stderr = self.run_command(command)
            performance_results.append(returncode == 0)
        
        performance_time = time.time() - start_time
        success_count = sum(performance_results)
        
        self.results['performance_tests'] = {
            'total': len(performance_commands),
            'passed': success_count,
            'time': performance_time
        }
        
        print(f"ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(performance_commands)} ì„±ê³µ ({performance_time:.2f}ì´ˆ)")
        return success_count == len(performance_commands)
    
    def run_coverage_analysis(self):
        """ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ë¶„ì„"""
        print("\nğŸ“ˆ ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ë¶„ì„ ì¤‘...")
        
        # pytest-cov ì„¤ì¹˜ í™•ì¸
        returncode, _, _ = self.run_command("python -c 'import pytest_cov'")
        if returncode != 0:
            print("ğŸ“¦ pytest-cov ì„¤ì¹˜ ì¤‘...")
            self.run_command("pip install pytest-cov", capture_output=False)
        
        # ì»¤ë²„ë¦¬ì§€ ì‹¤í–‰
        coverage_command = (
            f"python -m pytest {self.test_dir} "
            f"--cov=core --cov=excel --cov=email --cov=gui "
            f"--cov-report=term --cov-report=html:htmlcov "
            f"--cov-fail-under=80"
        )
        
        returncode, stdout, stderr = self.run_command(coverage_command)
        
        # ì»¤ë²„ë¦¬ì§€ ê²°ê³¼ íŒŒì‹±
        coverage_line = ""
        for line in stdout.split('\n'):
            if "TOTAL" in line and "%" in line:
                coverage_line = line
                break
        
        if coverage_line:
            coverage_percent = coverage_line.split()[-1].replace('%', '')
            print(f"ğŸ“Š ì½”ë“œ ì»¤ë²„ë¦¬ì§€: {coverage_percent}%")
            
            self.results['coverage'] = {
                'percentage': float(coverage_percent),
                'html_report': str(self.project_root / "htmlcov" / "index.html")
            }
        else:
            print("âš ï¸  ì»¤ë²„ë¦¬ì§€ ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.results['coverage'] = {'percentage': 0}
        
        return returncode == 0
    
    def generate_test_report(self):
        """í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report_path = self.project_root / "test_report.json"
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        total_time = sum(
            result.get('time', 0) 
            for result in self.results.values() 
            if isinstance(result, dict)
        )
        
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_time": total_time,
            "summary": {
                "unit_tests": self.results.get('unit_tests', {}),
                "integration_tests": self.results.get('integration_tests', {}),
                "performance_tests": self.results.get('performance_tests', {}),
                "coverage": self.results.get('coverage', {})
            },
            "recommendations": self._generate_recommendations()
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ì €ì¥ë¨: {report_path}")
        self._print_summary_report(report)
        
        return report_path
    
    def _generate_recommendations(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë°˜
        if 'unit_tests' in self.results:
            unit_results = self.results['unit_tests']
            if unit_results.get('failed', 0) > 0:
                recommendations.append("ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í•­ëª©ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
        
        # ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜
        if 'coverage' in self.results:
            coverage = self.results['coverage'].get('percentage', 0)
            if coverage < 80:
                recommendations.append(f"ì½”ë“œ ì»¤ë²„ë¦¬ì§€ê°€ {coverage}%ì…ë‹ˆë‹¤. 80% ì´ìƒìœ¼ë¡œ ê°œì„ ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            elif coverage >= 90:
                recommendations.append("ìš°ìˆ˜í•œ ì½”ë“œ ì»¤ë²„ë¦¬ì§€ì…ë‹ˆë‹¤!")
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê¸°ë°˜
        if 'performance_tests' in self.results:
            perf_results = self.results['performance_tests']
            if perf_results.get('passed', 0) < perf_results.get('total', 1):
                recommendations.append("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ í•­ëª©ì„ í™•ì¸í•˜ê³  ìµœì í™”í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
        
        return recommendations
    
    def _print_summary_report(self, report):
        """ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìš”ì•½ ë³´ê³ ì„œ")
        print(f"{'='*60}")
        print(f"ì‹¤í–‰ ì‹œê°„: {report['timestamp']}")
        print(f"ì´ ì†Œìš” ì‹œê°„: {report['total_time']:.2f}ì´ˆ")
        print(f"")
        
        # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
        if 'unit_tests' in report['summary']:
            unit = report['summary']['unit_tests']
            print(f"ğŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸:")
            print(f"   âœ… í†µê³¼: {unit.get('passed', 0)}ê°œ")
            print(f"   âŒ ì‹¤íŒ¨: {unit.get('failed', 0)}ê°œ")
            print(f"   â±ï¸  ì‹œê°„: {unit.get('time', 0):.2f}ì´ˆ")
        
        # í†µí•© í…ŒìŠ¤íŠ¸
        if 'integration_tests' in report['summary']:
            integration = report['summary']['integration_tests']
            status = "âœ… ì„±ê³µ" if integration.get('success', False) else "âŒ ì‹¤íŒ¨"
            print(f"ğŸ”— í†µí•© í…ŒìŠ¤íŠ¸: {status} ({integration.get('time', 0):.2f}ì´ˆ)")
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        if 'performance_tests' in report['summary']:
            perf = report['summary']['performance_tests']
            print(f"âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: {perf.get('passed', 0)}/{perf.get('total', 0)} ì„±ê³µ ({perf.get('time', 0):.2f}ì´ˆ)")
        
        # ì½”ë“œ ì»¤ë²„ë¦¬ì§€
        if 'coverage' in report['summary']:
            coverage = report['summary']['coverage']
            print(f"ğŸ“ˆ ì½”ë“œ ì»¤ë²„ë¦¬ì§€: {coverage.get('percentage', 0)}%")
            if 'html_report' in coverage:
                print(f"   ğŸ“Š ìƒì„¸ ë³´ê³ ì„œ: {coverage['html_report']}")
        
        print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in report['recommendations']:
            print(f"   â€¢ {rec}")
        
        print(f"{'='*60}")
    
    def main(self, args):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print("ğŸš€ ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°")
        print(f"ğŸ“ í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.project_root}")
        
        start_time = time.time()
        
        # ì˜ì¡´ì„± í™•ì¸
        self.check_dependencies()
        
        success = True
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        if args.integration:
            success &= self.run_integration_tests()
        elif args.performance:
            success &= self.run_performance_tests()
        elif args.fast:
            # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë§Œ (ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¼ë¶€)
            print("\nâš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
            success &= self.run_unit_tests()
        else:
            # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            success &= self.run_unit_tests()
            success &= self.run_integration_tests()
            
            if not args.skip_performance:
                success &= self.run_performance_tests()
            
            if args.coverage:
                self.run_coverage_analysis()
        
        # ë³´ê³ ì„œ ìƒì„±
        report_path = self.generate_test_report()
        
        total_time = time.time() - start_time
        
        if success:
            print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ {total_time:.2f}ì´ˆ)")
            print(f"ğŸš€ ì‹œìŠ¤í…œì´ í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ìƒíƒœì…ë‹ˆë‹¤.")
        else:
            print(f"\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì´ {total_time:.2f}ì´ˆ)")
            print(f"ğŸ”§ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        return 0 if success else 1


def main():
    """ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(
        description="ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        "--fast",
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰ (ë‹¨ìœ„ í…ŒìŠ¤íŠ¸)"
    )
    
    parser.add_argument(
        "--integration",
        action="store_true", 
        help="í†µí•© í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰"
    )
    
    parser.add_argument(
        "--performance",
        action="store_true",
        help="ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰"
    )
    
    parser.add_argument(
        "--coverage",
        action="store_true",
        help="ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ë¶„ì„ í¬í•¨"
    )
    
    parser.add_argument(
        "--skip-performance",
        action="store_true",
        help="ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°"
    )
    
    args = parser.parse_args()
    
    runner = TestRunner()
    return runner.main(args)


if __name__ == "__main__":
    sys.exit(main())